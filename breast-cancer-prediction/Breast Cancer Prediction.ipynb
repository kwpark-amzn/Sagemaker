{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "42b5e80b-ad1d-4335-a1f7-10a91127e3dc"
    }
   },
   "source": [
    "# 유방암 예측\n",
    "_**유방 질량 이미지에서 파생된 feature 로 SageMaker의 linear-learner 를 사용하여 유방암 예측**_\n",
    "\n",
    "---\n",
    "\n",
    "## 차례\n",
    "\n",
    "1. [배경](#배경)\n",
    "1. [설정](#설정)\n",
    "1. [데이터](#데이터)\n",
    "1. [훈련](#훈련)\n",
    "1. [호스팅](#호스팅)\n",
    "1. [예측](#예측)\n",
    "1. [확장](#확장)\n",
    "\n",
    "---\n",
    "\n",
    "## 배경\n",
    "이 노트북은 예측을 위해 `linear models` 을 요구하는 문제해결 애플리케이션을 위해 Sagemaker 의 알고리즘을 사용하는 법을 보여줍니다. <br />\n",
    "이 예에서 우리는 유방암 예측을 위해 UCI 의 유방암 진단 데이터 셋을 가져옵니다. <br />\n",
    "목표는 이 데이터 세트를 사용하여 유방종 이미지가 양성 또는 악성 종양을 나타내는지 여부에 대한 예측 모델을 구축하는 것입니다. <br />\n",
    "\n",
    "* Sagemaker 사용을 위한 기본적인 환경 구축\n",
    "* Sagemaker 알고리즘이 사용할 수 있도록 데이터셋을 protobuf 포맷으로 변환하고 S3 에 업로드\n",
    "* SageMaker linear learner 알고리즘으로 훈련\n",
    "* 훈련된 모델을 호스팅\n",
    "* 훈련된 모델을 사용하여 스코어링\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 설정\n",
    "\n",
    "다음을 설정하는 것으로 시작 해보겠습니다.\n",
    "\n",
    "* SageMaker 역할은 데이터에 대한 학습 및 호스팅 액세스 권한을 부여하는 데 사용됩니다. <br />\n",
    "  아래 코드는 SageMaker 노트북 인스턴스에서 사용하는 것과 동일한 역할을 사용합니다. 그렇지 않은 경우 SageMakerFullAccess 정책이 연결된 역할의 전체 ARN을 지정합니다.\n",
    "* 모델 객체를 훈련하고 저장하는 데 사용하려는 S3 버킷 지정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "isConfigCell": true,
    "nbpresent": {
     "id": "6427e831-8f89-45c0-b150-0b134397d79a"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket and prefix\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "\n",
    "prefix = (\n",
    "    \"sagemaker/DEMO-breast-cancer-prediction\"  # place to upload training files within the bucket\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b2548d66-6f8f-426f-9cda-7a3cd1459abd"
    }
   },
   "source": [
    "이제 필요한 Python 라이브러리를 가져옵니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "bb88eea9-27f3-4e47-9133-663911ea09a9"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import sagemaker.amazon.common as smac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "142777ae-c072-448e-b941-72bc75735d01"
    }
   },
   "source": [
    "---\n",
    "## 데이터\n",
    "\n",
    "\n",
    "> Dua, D. and Graff, C. (2019). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "> Breast Cancer Wisconsin (Diagnostic) Data Set [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)].\n",
    "\n",
    "> _Also see:_ Breast Cancer Wisconsin (Diagnostic) Data Set [https://www.kaggle.com/uciml/breast-cancer-wisconsin-data].\n",
    "\n",
    "다음 코드는 위 데이터 소스 위치로부터 데이터를 로컬 폴더에 다운로드하여 저장한 후에 파일의 이름을 data.csv 로 변경합니다. 이 작업은 조금 시간이 소요될 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "f8976dad-6897-4c7e-8c95-ae2f53070ef5"
    }
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "filename = \"wdbc.csv\"\n",
    "s3.download_file(\"sagemaker-sample-files\", \"datasets/tabular/breast_cancer/wdbc.csv\", filename)\n",
    "data = pd.read_csv(filename, header=None)\n",
    "\n",
    "# 컬럼명 지정\n",
    "data.columns = [\n",
    "    \"id\",\n",
    "    \"diagnosis\",\n",
    "    \"radius_mean\",\n",
    "    \"texture_mean\",\n",
    "    \"perimeter_mean\",\n",
    "    \"area_mean\",\n",
    "    \"smoothness_mean\",\n",
    "    \"compactness_mean\",\n",
    "    \"concavity_mean\",\n",
    "    \"concave points_mean\",\n",
    "    \"symmetry_mean\",\n",
    "    \"fractal_dimension_mean\",\n",
    "    \"radius_se\",\n",
    "    \"texture_se\",\n",
    "    \"perimeter_se\",\n",
    "    \"area_se\",\n",
    "    \"smoothness_se\",\n",
    "    \"compactness_se\",\n",
    "    \"concavity_se\",\n",
    "    \"concave points_se\",\n",
    "    \"symmetry_se\",\n",
    "    \"fractal_dimension_se\",\n",
    "    \"radius_worst\",\n",
    "    \"texture_worst\",\n",
    "    \"perimeter_worst\",\n",
    "    \"area_worst\",\n",
    "    \"smoothness_worst\",\n",
    "    \"compactness_worst\",\n",
    "    \"concavity_worst\",\n",
    "    \"concave points_worst\",\n",
    "    \"symmetry_worst\",\n",
    "    \"fractal_dimension_worst\",\n",
    "]\n",
    "\n",
    "# 데이터 저장\n",
    "data.to_csv(\"data.csv\", sep=\",\", index=False)\n",
    "\n",
    "# 데이터 파일의 모양(shape) 프린트\n",
    "print(data.shape)\n",
    "\n",
    "# 최상위 몇개의 행 표시 \n",
    "display(data.head())\n",
    "\n",
    "# 데이터 객체를 표시\n",
    "display(data.describe())\n",
    "\n",
    "# we will also summarize the categorical field diganosis\n",
    "# 필드 분류를 요약 \n",
    "display(data.diagnosis.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주요 관찰 결과:\n",
    "* 데이터는 569개의 관측값과 32개의 컬럼을 가지고 있습니다. \n",
    "* 첫번째 필드는 'id' 입니다.\n",
    "* 두번째 필드는 'diagnosis' 이고 악성('M' = Malignant)과 양성('B' = Benign)에 대한 진단 지표입니다.\n",
    "* 예측에 활용할 수 있는 30개의 다른 숫자형 feature (특성값) 들이 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features 와 Labels 생성\n",
    "#### 아래 코드는 데이터를 80% 의 training 데이터, 10% 의 validation 용 데이터, 10% test 용 데이터로 나눕니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_split = np.random.rand(len(data))\n",
    "train_list = rand_split < 0.8\n",
    "val_list = (rand_split >= 0.8) & (rand_split < 0.9)\n",
    "test_list = rand_split >= 0.9\n",
    "\n",
    "data_train = data[train_list]\n",
    "data_val = data[val_list]\n",
    "data_test = data[test_list]\n",
    "\n",
    "train_y = ((data_train.iloc[:, 1] == \"M\") + 0).to_numpy()\n",
    "train_X = data_train.iloc[:, 2:].to_numpy()\n",
    "\n",
    "val_y = ((data_val.iloc[:, 1] == \"M\") + 0).to_numpy()\n",
    "val_X = data_val.iloc[:, 2:].to_numpy()\n",
    "\n",
    "test_y = ((data_test.iloc[:, 1] == \"M\") + 0).to_numpy()\n",
    "test_X = data_test.iloc[:, 2:].to_numpy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ff9d10f9-b611-423b-80da-6dcdafd1c8b9"
    }
   },
   "source": [
    "\n",
    "이제 데이터 세트를 Amazon SageMaker 알고리즘에서 사용하는 recordIO-wrapped protobuf 형식으로 변환한 다음 이 데이터를 S3에 업로드합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "cd8e3431-79d9-40b6-91d1-d67cd61894e7"
    }
   },
   "outputs": [],
   "source": [
    "train_file = \"linear_train.data\"\n",
    "\n",
    "f = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(f, train_X.astype(\"float32\"), train_y.astype(\"float32\"))\n",
    "f.seek(0)\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train\", train_file)\n",
    ").upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "71cbcebd-a2a5-419e-8e50-b2bc0909f564"
    }
   },
   "source": [
    "\n",
    "다음으로 유효성 검사 데이터 세트를 변환하고 업로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "bd113b8e-adc1-4091-a26f-a426149fe604"
    }
   },
   "outputs": [],
   "source": [
    "validation_file = \"linear_validation.data\"\n",
    "\n",
    "f = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(f, val_X.astype(\"float32\"), val_y.astype(\"float32\"))\n",
    "f.seek(0)\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"validation\", validation_file)\n",
    ").upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f3b125ad-a2d5-464c-8cfa-bd203034eee4"
    }
   },
   "source": [
    "---\n",
    "## 훈련\n",
    "\n",
    "Amazon SageMaker의 Linear Learner는 실제로 각각 약간 다른 하이퍼파라미터를 사용하여 여러 모델을 병렬로 맞춘 다음 가장 잘 맞는 모델을 반환합니다. <br />\n",
    "이 기능은 자동으로 활성화됩니다. 다음과 같은 매개변수를 사용하여 이에 영향을 줄 수 있습니다. <br />\n",
    "\n",
    "- 'num_models' : 모델 실행의 전체 수. 최적에 가까운 솔루션을 찾기 위해 가까운 매개변수 값을 가진 모델을 선택합니다. 이번 실습에서는 최대값인 32를 사용합니다.\n",
    "- 'loss' : 모델 추정치의 실수에 페널티를 부여하는 방법을 제어. 이번 실습에서는 데이터를 정리하는 데 많은 시간을 소비하지 않았으므로 absolute loss 을 사용하고 absolute loss 은 이상값 (outlier) 에 덜 민감합니다.\n",
    "- 'wd' 또는 'l1' : 정규화를 제어. 정규화는 우리의 추정치가 훈련 데이터에 너무 미세하게 조정되는 것을 방지함으로써 모델 과적합을 방지할 수 있습니다. 이번 실습에서는 이 매개변수를 기본 \"자동\"으로 남겨둘 것입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker 의 linear-learner 를 훈련하고 호스팅하기 위해 사용되는 컨테이너 이미지 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "container = image_uris.retrieve(region=boto3.Session().region_name, framework=\"linear-learner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "397fb60a-c48b-453f-88ea-4d832b70c919"
    }
   },
   "outputs": [],
   "source": [
    "linear_job = \"DEMO-linear-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "print(\"Job name is:\", linear_job)\n",
    "\n",
    "linear_training_params = {\n",
    "    \"RoleArn\": role,\n",
    "    \"TrainingJobName\": linear_job,\n",
    "    \"AlgorithmSpecification\": {\"TrainingImage\": container, \"TrainingInputMode\": \"File\"},\n",
    "    \"ResourceConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.c4.2xlarge\", \"VolumeSizeInGB\": 10},\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/train/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"ShardedByS3Key\",\n",
    "                }\n",
    "            },\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"None\",\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/validation/\".format(bucket, prefix),\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"RecordWrapperType\": \"None\",\n",
    "        },\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": \"s3://{}/{}/\".format(bucket, prefix)},\n",
    "    \"HyperParameters\": {\n",
    "        \"feature_dim\": \"30\",\n",
    "        \"mini_batch_size\": \"100\",\n",
    "        \"predictor_type\": \"regressor\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"num_models\": \"32\",\n",
    "        \"loss\": \"absolute_loss\",\n",
    "    },\n",
    "    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 60 * 60},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "이제 방금 생성한 매개변수를 사용하여 SageMaker의 분산 관리 훈련작업을 시작합니다. <br />\n",
    "훈련이 관리되기 때문에 작업이 끝날 때까지 기다릴 필요가 없지만 이 경우 boto3의 'training_job_completed_or_stopped' 대기자를 사용하여 작업이 시작되었는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "\n",
    "sm.create_training_job(**linear_training_params)\n",
    "\n",
    "status = sm.describe_training_job(TrainingJobName=linear_job)[\"TrainingJobStatus\"]\n",
    "print(status)\n",
    "sm.get_waiter(\"training_job_completed_or_stopped\").wait(TrainingJobName=linear_job)\n",
    "if status == \"Failed\":\n",
    "    message = sm.describe_training_job(TrainingJobName=linear_job)[\"FailureReason\"]\n",
    "    print(\"Training failed with the following error: {}\".format(message))\n",
    "    raise Exception(\"Training job failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2adcc348-9ab5-4a8a-8139-d0ecd740208a"
    }
   },
   "source": [
    "---\n",
    "## 호스팅\n",
    "\n",
    "이제 데이터에 대한 linear 알고리즘을 학습했으므로 나중에 호스팅할 수 있는 모델을 설정해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c88fb868-01d2-4991-8953-28814c022bdc"
    }
   },
   "outputs": [],
   "source": [
    "linear_hosting_container = {\n",
    "    \"Image\": container,\n",
    "    \"ModelDataUrl\": sm.describe_training_job(TrainingJobName=linear_job)[\"ModelArtifacts\"][\n",
    "        \"S3ModelArtifacts\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "create_model_response = sm.create_model(\n",
    "    ModelName=linear_job, ExecutionRoleArn=role, PrimaryContainer=linear_hosting_container\n",
    ")\n",
    "\n",
    "print(create_model_response[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 설정하고 나면 모델을 호스팅할 엔드포인트에 대해 설정합니다. \n",
    "\n",
    "1. 호스팅에 사용할 EC2 인스턴스 유형\n",
    "2. 인스턴스의 초기 갯수\n",
    "3. 호스팅 모델명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_endpoint_config = \"DEMO-linear-endpoint-config-\" + time.strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", time.gmtime()\n",
    ")\n",
    "print(linear_endpoint_config)\n",
    "create_endpoint_config_response = sm.create_endpoint_config(\n",
    "    EndpointConfigName=linear_endpoint_config,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m4.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelName\": linear_job,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "엔드포인트를 구성하는 방법을 지정했으므로 이제 엔드포인트를 생성할 수 있습니다. <br />\n",
    "이것은 백그라운드에서 수행할 수 있지만 지금은 엔드포인트의 상태를 업데이트하는 루프를 실행하여 언제 사용할 준비가 되었는지 알도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "linear_endpoint = \"DEMO-linear-endpoint-\" + time.strftime(\"%Y%m%d%H%M\", time.gmtime())\n",
    "print(linear_endpoint)\n",
    "create_endpoint_response = sm.create_endpoint(\n",
    "    EndpointName=linear_endpoint, EndpointConfigName=linear_endpoint_config\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sm.describe_endpoint(EndpointName=linear_endpoint)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "sm.get_waiter(\"endpoint_in_service\").wait(EndpointName=linear_endpoint)\n",
    "\n",
    "resp = sm.describe_endpoint(EndpointName=linear_endpoint)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "if status != \"InService\":\n",
    "    raise Exception(\"Endpoint creation did not succeed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측\n",
    "### 테스트 데이터를 이용한 예측\n",
    "\n",
    "이제 호스팅된 엔드포인트가 있으므로 여기에서 통계적 예측을 생성할 수 있습니다. <br />\n",
    "모델이 얼마나 정확한지 이해하기 위해 테스트 데이터 세트에서 예측해 보겠습니다.\n",
    "분류 정확도를 측정하기 위한 많은 메트릭이 있습니다. 일반적인 예에는 다음이 포함됩니다. \n",
    "\n",
    "- Precision (정밀도)\n",
    "- Recall\n",
    "- F1 measure (F1 측정값)\n",
    "- Area under the ROC curve - AUC\n",
    "- Total Classification Accuracy (총 분류정확도)\n",
    "- Mean Absolute Error (평균절대오차)\n",
    "\n",
    "이 예에서 우리는 작업을 단순하게 유지하기 위해 Total Classification Accuracy 를 선택 지표로 사용할 것입니다. <br/>\n",
    "또한 linear learner 가 이 메트릭을 사용하여 최적화되었기 때문에 MAE(Mean Absolute Error)를 평가할 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### array 를 csv 로 변환하기 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np2csv(arr):\n",
    "    csv = io.BytesIO()\n",
    "    np.savetxt(csv, arr, delimiter=\",\", fmt=\"%g\")\n",
    "    return csv.getvalue().decode().rstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "예측값을 얻기 위해 endpoint 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client(\"runtime.sagemaker\")\n",
    "\n",
    "payload = np2csv(test_X)\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=linear_endpoint, ContentType=\"text/csv\", Body=payload\n",
    ")\n",
    "result = json.loads(response[\"Body\"].read().decode())\n",
    "test_pred = np.array([r[\"score\"] for r in result[\"predictions\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "모든 인스턴스를 예측하기 위해 대다수 클래스를 사용하는 기준선 평균절대예측오류와 선형학습자 기반 평균절대예측오류를 비교합니다. <br/>\n",
    "- 기준선 기반 평균절대예측오류(Baseline Mean Abolute Error) - Baseline MAE <br/>\n",
    "- 선형학습자 기반 평균절대예측오류(Linear Mean Absolute Error) - Linear MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mae_linear = np.mean(np.abs(test_y - test_pred))\n",
    "test_mae_baseline = np.mean(\n",
    "    np.abs(test_y - np.median(train_y))\n",
    ")  ## training median as baseline predictor\n",
    "\n",
    "print(\"Test MAE Baseline :\", round(test_mae_baseline, 3))\n",
    "print(\"Test MAE Linear:\", round(test_mae_linear, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "예측에 대해 0.5의 분류 임계값을 사용하여 예측 정확도를 비교하고 훈련 데이터 세트로부터 다수 클래스 예측과 비교해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_class = (test_pred > 0.5) + 0\n",
    "test_pred_baseline = np.repeat(np.median(train_y), len(test_y))\n",
    "\n",
    "prediction_accuracy = np.mean((test_y == test_pred_class)) * 100\n",
    "baseline_accuracy = np.mean((test_y == test_pred_baseline)) * 100\n",
    "\n",
    "print(\"Prediction Accuracy:\", round(prediction_accuracy, 1), \"%\")\n",
    "print(\"Baseline Accuracy:\", round(baseline_accuracy, 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자원삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=linear_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 확장\n",
    "\n",
    "- 우리의 linear 모델은 유방암을 잘 예측하고 92%에 가까운 전체 정확도를 가지고 있습니다. 하이퍼 파라미터, 손실 함수 등의 다른 값으로 모델을 다시 실행하고 예측이 개선되는지 확인할 수 있습니다. <br/> \n",
    "  이러한 하이퍼 파라미터에 대한 추가 조정으로 모델을 다시 실행하면 더 정확한 샘플 외 예측을 제공할 수 있습니다.\n",
    "- 우리는 또한 많은 feature engineering 을 하지 않았습니다. 여러 feature 의 외적/상호작용을 고려하여 추가 feature 를 생성할 수 있습니다. \n",
    "- 추가 확장으로 XGBoost, MXNet 등과 같은 SageMaker를 통해 사용할 수 있는 많은 비선형 모델을 사용할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the License). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the license file accompanying this file. This file is distributed on an AS IS BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
